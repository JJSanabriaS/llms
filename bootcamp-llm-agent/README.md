# Aplica√ß√µes de IA com Agentes Aut√¥nomos 
Este projeto foi desenvolvido para ensinar conceitos b√°sicos relativos para o desenvolvimento de agentes usando grandes modelos de linguagem (LLMs, *Large Language Models*).

O foco ser√° o desenvolvimento em **Python** de um assistente capaz de responder perguntas sobre filmes, armazenados como um knowledge Graph em [neo4j](https://neo4j.com).

Apesar de n√£o se desenvolvido em Java, os conceitos aqui apresentados certamente podem ser extrapolados para outros contextos.

## Como utilizar este projeto
1. **J√° tenho uma conta no GitHub**

- **Quero evoluir meu projeto a partir desse:** Nesse caso, d√™ um fork nesse projeto. Assim voc√™ poder√° ampliar esse projeto no seu pr√≥prio GitHub, adicionando o seu pr√≥prio c√≥digo, o que eu recomendo muito.
- **Quero apenas acompanhar esse projeto:** Caso deseje apenas acompanhar a evolu√ß√£o desse projeto para as pr√≥ximas monitorias, d√™ um watch, assim ser√° informado sobre as novas altera√ß√µes desse projeto.

Considere dar uma ‚Äúestrela‚Äú ao projeto se voc√™ achar ele √∫til **üòä**!

2. **N√£o tenho um conta no GitHub**

Primeiramente, recomendo que crie sua conta no GitHub e siga uma das op√ß√µes do item 1. Caso opte por n√£o criar a conta no GitHub, voc√™ pode:

- **Tenho o Git instalado em minha m√°quina:** clone este projeto com o comando:

‚Äúgit clone <https://github.com/lborro/bootcamp-llm-agent>

‚Ä¶ e voc√™ poder√° alterar esse c√≥digo na sua IDE favorita.

- **N√£o tenho o Git instalado em minha m√°quina:** voc√™ pode fazer o dowload do projeto clicando no bot√£o verde ‚ÄúCode‚Äú e depois em ‚ÄúDownload ZIP‚Äù.


## Configura√ß√£o do ambiente

### OpenAI
Iremos utilizar os modelos de linguagem e emmbeddigs da OpenAI. Logo, √© necess√°rio criar uma conta na [OpenAI](https://platform.openai.com/) e gerar uma API Key.

### Docker
Necess√°ria a instala√ß√£o do Docker e docker-compose para a execu√ß√£o do assistente.

### Python - Ambiente virtual

Vamos instalar o Ananconda para o gerenciamento dos ambientes virtuais em Python. As instru√ß√µes de instala√ß√£o podem ser vistas [aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html).

Ap√≥s instalado o Anaconda, precisamos criar um ambiente virtual

`conda create -n llm-agent python=3.9`

Ative ent√£o o ambiente virtual rec√©m criado

`conda activate llm-agent`

Vamos agora instalar as depend√™ncias para trabalharmos com o desenvolvimento de um agente usando LLMs.

`pip install -r requirements.txt`

### Base de dados

Para subir o servi√ßo do neo4j, vamos utilizar o seguinte comando:

`docker-compose up -d`

Em seguida, faremos a ingest√£o do cat√°lgo de filmes. Na pasta `notebooks`, h√° um Jupyter Notebook para essa finalidade: `ingest_data.ipynb`. 

## Vis√£o geral da solu√ß√£o

O n√∫cleo do bot conversacional √© um agente [ReAct](https://arxiv.org/abs/2210.03629), projetado para extrair informa√ß√µes de um Knowledge Graph em neo4j. Especificamente, o bot √© composto por um agente e um conjunto de ferramentas. Durante uma intera√ß√£o com o bot, o agente decide qual a√ß√£o tomar, que pode incluir o uso de uma ferramenta.
Se o agente determinar que uma a√ß√£o deve ser executada (como a ativa√ß√£o de uma ferramenta), as ferramentas ser√£o acionadas e os resultados ser√£o retornados ao agente. Caso o agente n√£o solicite a execu√ß√£o de ferramentas, a intera√ß√£o ser√° conclu√≠da com uma resposta ao usu√°rio.

### Implementa√ß√£o do agente ReAct
A implementa√ß√£o agente ReAct foi feita usando LangChain (`langchain v0.2`) e  LangGraph (`langgraph`). Mais especificamente, o agente funciona como grafo de estados (vide Figura) composto por tr√™s componentes principais:

- Estado (State):  Estrutura de dados que armazena o status atual o agente.
- N√≥s (Nodes): Fun√ß√µes Python que codificam a l√≥gica de um agente. Elas recebem o estado atual como entrada, realizam alguma a√ß√£o e retornam um estado atualizado.
- Arestas (Edges): Fun√ß√µes Python que determinam o pr√≥ximo n√≥ de acordo com o estado atual.

![ ](https://raw.githubusercontent.com/lborro/bootcamp-llm-agent/main/img/react-agent.png)


O n√≥ principal (agent) executa um modelo de linguagem (Azure gpt-4o vers√£o 2024-05-13) para determinar se precisa buscar novas informa√ß√µes da base de dados relacional ou se j√° √© capaz de dar uma resposta adequada √† intera√ß√£o do usu√°rio. A execu√ß√£o √© finalizada se o agente n√£o possui mais nenhuma a√ß√£o a ser executada.

### Por que LangChain?
LangChain √© um framework de c√≥digo aberto para criar aplica√ß√µes com modelos de LLMs. Esses modelos, pr√©-treinados com grandes volumes de dados, podem responder a perguntas ou criar imagens a partir de textos. LangChain fornece ferramentas para melhorar a personaliza√ß√£o e precis√£o dessas respostas. Nesse sentido, desenvolvedores podem criar novos prompts ou ajustar os existentes e permitir que os modelos acessem novos dados sem retreinamento.



## Contato
Se precisar de ajuda ou quiser trocar uma ideia, sinta-se √† vontade para me contatar:

- [LinkedIn](https://www.linkedin.com/in/lborro/)